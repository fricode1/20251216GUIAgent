# 实验背景

同事指出创新性还有提升空间

# 实验目的

逻辑思考

# 实验步骤

## 逻辑分析

### 我真的不希望有个好的大模型吗？

你难道不希望有个大模型，把页面发给他，它告诉你每个元素的语义和操作方法吗？

你现在手动找元素的id和操作方法不是很费劲吗？

其实你手动找到1次，就是大模型的一条训练数据。

## 实验：Gemini 3 flash 能否根据DOM找到指定车次的订票按钮？

这个功能我手动操作很麻烦

12306.html 具有 910,925 tokens，花费 0.45 美元。

#ticket_24000C22390Z_01_02 .btn72

回答正确。

## 实验：Nano banana 能否根据截图，在指定车次的预定按钮上绘制红色矩形框？

回答错误。

虽然这不是图生文大模型而是图生图大模型，却也反应了多模态大模型的能力未达预期。

## 实验：使用 StageHand 在 12306 中填写出发地

其开发的 director.ai 可以直接交互，不需要本地部署。

但是在意料之中失败了，见 stagehand无法填写出发地。这需要专业前端工程师才能做对。

在这个案例中，stagehand正确找到了元素，但是错误地执行了操作。应该用 tab.actions.type('taian') 而非 tab.actions.input('taian')

这是因为该文本框必须识别 keyup 事件。type 包含了 keyup 事件，而 input 没有包含 keyup 事件。

很多像 12306 这样的复杂前端，会监听键盘事件（keydown, keyup）。
input('taian') 通常只是修改了 DOM 元素的 value 属性，没有触发 JS 监听器。
type('taian') 模拟了真实的物理按键，会触发整套事件流。
AI 的局限： 现有的 AI Agent 大多是在静态 HTML 或截图上训练的，它们缺乏对网页动态交互逻辑（Event Listeners）的感知。AI 知道它是输入框，但不知道这个输入框背后有一双“盯着键盘看”的眼睛。

## 学习 xpath 相关知识

为什么 xpath=/html[1]/body[1]/div[1]/div[3]/div[2]/div[1]/div[1]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/input[2]

可以表示12306网站的出发地输入框，而 '#fromStationText' 同样可以表示同一元素？

这两个字符串分别代表了定位同一个 HTML 元素的两种不同策略：绝对路径定位（Absolute XPath） 和 唯一标识符定位（ID Selector）。

## ai 输出数字和输出 css选择器有什么区别吗？

ai看到的：[13] <class = abc>

ai可以进行两种输出：[13] 或者 <class = abc> 其实本质上没有区别。

如果你觉得ai输出字符可能出错，那么ai输出数字同样可能出错。

有时我们甚至希望ai能输出更健壮的css选择器，比如 eles('.abc')[3]

## 网站地图里的元素ID、含义、操作，是AI生成的还是手工编制的，这是根本性的变化。

我能够根据dom写出来，ai肯定也能根据dom写出来。

（但是我能，AI就能这个概念不能简单泛化。比如对于整个流程的把握，我可以，ai就很难。这种原子性的事情，才适用“我可以，AI就可以”）。比如：

为什么要先买票再选座？如果泰安没票了，是买中转票还是改签？
逻辑：策略 -> 目标 -> 状态转移。这涉及长程规划（Long-horizon Planning）和复杂的业务逻辑。
结论：“我可以，AI 很难。” 目前的 AI 在这一层级容易产生幻觉或迷失目标。

## 我非得选择 drissionpage 不可吗？

我目前只知道这一种能够正确填写12306文本框的方法。

我试过的所有 Web Agent，在这一案例上统统失败。

在 bua 上，其核心代码里甚至试图模拟键盘事件和 bubble，但是由于其中一行bubble的时机不合适，反而弄巧成拙。

这个问题的根本不是更强的 GPT-5，而是更懂浏览器底层特性的“交互引擎”。 

## 如果是基于 drissionpage，我该怎么做？

我想专注于执行器：只针对当前页面，选择正确元素ID，正确理解其语义，正确执行动作。

nanobrowser正是规划器和执行器分离的。它们完全可以采用各自不同的模型。

完整的GUI Agent的全链路控制需要考虑过去做了什么，也需要考虑将来要做什么。训练集不好构建，涉及动作流。

如果只限AI操作当前页面元素，训练集好构建。只涉及1个动作。

而 RPA 由人工写的 ele.click('.abc') 不是AI。

**训练输入（Input）**
1. 当前页面的简化 DOM (Simplified DOM)：只保留关键标签（input, button, a）及其关键属性（id, class, placeholder, text, aria-label）。
2. 用户的原子意图 (Atomic Intent)：“在出发地输入泰安”。

**训练目标（Label）：**

tab.actions.click('#fromStationText'); tab.actions.type('taian') 

## 我目前写的东西，能直接用作数据集吗？

点击正常过车信息按钮：tab.ele('监控点位信息').wait.enabled().click(); time.sleep(3) 可加载监控点位信息查询界面。

在监控点位信息查询界面，点击查询按钮：tab.ele( '查询 ').wait.enabled().click() 可获得各监控点信息

查询结果是一个个的卡片，表示各监控点信息：tab.eles('.card-item basic-wrap BS-subInfoCard_wrap')

AI说的对：需要补齐HTML快照。

## 同事提出，将来如果你的产品要在数百个城市推广，难道要为每个网站都构建地图吗？

同事希望我研发的 Web Agent 具有通用性。

同事提出，将来如果你的产品要在数百个城市推广，难道要为每个网站都做为 Web Agent 做定制化适配吗？

可事实是这不现实（现有 Web Agent 连12306输入框都填不准的例子。）

这就比如，如果让我研发一个不用遥控器的人形机器人。

在商业逻辑（Scalability）的角度：如果一个产品需要靠人力堆代码去适配每一个城市、每一个网站，那这个产品的边际成本太高，不具备商业美感。

在工程实践（Reliability）的角度：网页结构千奇百怪、动态加载、反爬机制、不规范的标签（如 12306），现有的 LLM + Web Agent 技术栈确实还没达到“一刀切”的成熟度。

如何处理这个问题并推动项目落地：

1. 重新定义“通用性”：不是“全部通用”，而是“架构通用”

我们不会为每个网站做硬编码（Hard-coding）式的定制化。

通用性不代表“零适配”，而是“低成本适配”。

完全定制化（RPA时代）： 为 A 站写一套 XPath 脚本，B 站写一套。网站一改版，脚本全挂。

理想通用化（AGI时代）： 像人一样，看到任何网页都能直接上手。目前做不到（比如 12306 例子）。

折中方案： 研发一个**“通用大脑+插件式网站地图”**。

核心逻辑（如：拆解任务、处理异常、分析状态）是通用的。

针对不同城市的网站，只需要提供一份轻量级的**“领域描述文件（Schema/Metadata）”**，而不是重写代码。

# 实验结果

进一步明确了该领域的事实和逻辑。