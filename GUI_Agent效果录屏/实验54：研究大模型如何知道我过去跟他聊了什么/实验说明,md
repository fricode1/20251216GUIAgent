# 实验背景

我在用 chatbot 的时候，告诉 chatbot，我叫小明。接下来，我问 chatbot，我是谁，chatbot 能够正确回复。

我在用 curl 调用大模型的时候，告诉大模型，我叫小明。接下来，我再次用 curl 调用大模型，问大模型我是谁，大模型不能正确回复

# 实验目的

弄懂原因

# 实验步骤

## 问gemini

大模型（LLM）本身是“无状态”的（Stateless），而 Chatbot 产品在背后为你维护了“状态”（State/Context）。

你在使用 ChatGPT 或 Claude 的网页版时，感觉它有记忆，是因为前端程序（对话框界面）在替你背书包。
当你进行第二轮对话时，Chatbot 程序实际上在后台做了以下操作：
它把“第一轮你的话”记录下来。
它把“第一轮它的回复”记录下来。
当你输入“第二轮你的话”时，它会把 [历史记录 + 当前问题] 拼成一个超长的字符串，一次性发给模型。

## 在 chatbot中，我与大模型聊天，我一开始传递给大模型一个很大的文件，后续持续针对该文件进行提问，这个流程是怎样的

当你把文件丢给 Chatbot 时，系统并不会直接把文件塞给大模型，而是基于rag把文件存入向量库。

当对话时，从向量库调用文件相关内容，再放入上下文。

## 如果我自己开发chatbot，历史消息需要我亲自处理吗

是的。

## 如果是一个支持很长上下文的模型，且真的给它很长的上下文，那么它的响应速度相比很短上下文有什么变化

会慢些，但有 context caching/前缀缓存优化之类技术优化。

所以如果采用滑动历史反而会降低命中率。但有时不得不做，这是因为总上下文长度毕竟有限。

## 我用 curl 调用自己部署的大模型，跟 context caching 有什么关系呢？

我其实是在跟自己部署的推理后端打交道，涉及到 KV chche。

## 工具调用不是模型的能力吗？跟推理后端有什么关系？

当你调用 OpenAI 格式的接口时，你会传一个 tools 列表（JSON 格式）。

- 模型的视角：模型根本看不见原始的 JSON 列表。它只能看见一段长长的文本（Prompt）。
- 后端（vLLM）的作用：它必须负责把你的 tools 列表，按照该模型特定的格式（比如 Llama 3 和 Qwen 的格式完全不同），准确地插入到 System Prompt 中。
- 为什么会出 Bug：如果 vLLM 的 Jinja2 模板写错了一个字符，或者没对齐官方的 Prompt 格式，模型就会产生误解，导致不调用工具或者格式报错。    

# 实验结果

完成