# 实验背景

20251230给同事做演示（实验31），结论是接下来要规划接下来三个月要做成什么事情，所以要有对应方案，所以要有PPT

# 实验目的

制作方案PPT

# 实验步骤

## 明确PPT文案

- 目标：实现一个具体任务
- 任务描述：先在“我们的平台”上执行“以文搜图”，将搜索到的图片流转到“海康视综平台”，执行“以图搜档”
- 任务意义：跨系统 + 文件中转
- 任务时间：三个月

## 准备素材

### 我们的平台上进行以文搜图的步骤

获取相关操作步骤的截图
- 录屏？
- 截图？
- 两者都要？

先截图。截图不行再说。

中止：经与同事讨论，得知，演示其实没有必要再做了。为什么呢？
1. 现在是直接用了别人的东西，你做了什么呢？
2. 现在的演示已经足够了。

## 调整思路

调整思路，好好想想到底要做怎样的PPT。

## mcp

能不能以mcp为出发点？将每个平台作为一个mcp，放置其知识库？因为有专门操作谷歌邮箱的MCP。MCP什么用？MCP和Agent的关系如何？系统研究一下。

用户指令： “分析我最近三个月的支出并生成报表。”
Agent 推理： “我需要访问用户的数据库，并使用绘图工具。”
MCP 的作用：
Agent 通过 MCP Client 发出请求。
连接到 PostgreSQL MCP Server 读取交易记录。
连接到 Google Sheets MCP Server 写入数据。

好像不太行。比如说，一个数据库产品会推出其对应的MCP，这样大模型就能与该数据库交互了，否则大模型无法与数据库交互。这不是我想要的。

其实操作浏览器的MCP才是真正的MCP。大模型调用这个mcp可以操作浏览器。

## cluade skills

除了 claude 都没法用。

## 从实际情况考虑

现在，已经有 Browser Use Agent 领域的开源项目能够执行浏览器自动化操作。但是，其成功率有限。因为面对复杂Web应用系统，功能繁杂，如果没有专业知识，则无法正确执行。因此如何让agent平台特定的专业知识是关键所在。

一个方向是从说明书入手。将说明书提取成纯文本。

将纯文本传给豆包，问他点问题。他老是自动联网搜索，我还是问Gemini吧。

问：根据文档，如果有一个犯人昨天下午越狱了，我该如何操作系统？

答：
针对您提到的“特定刑事案件犯罪嫌疑人追踪”场景，根据《InfovisionPVIA 视频图像综合应用平台使用说明书》，您可以按照以下实战流程进行操作。
该平台集成了海康威视的多种智能算法，建议采取“回溯搜寻、轨迹研判、实时布控、深度战法”的综合操作策略：
第一阶段：回溯搜寻（确定嫌疑人最后落脚点）
图片搜人（智图研判）：
进入“智能搜索 -> 智图研判”模块。
上传照片： 上传该犯人的近照（人脸或人体图片）。
设置条件： 时间范围选择“自定义”，起止时间设为“昨天下午越狱时刻”至今；地点范围可先选择“全选”或嫌疑人可能经过的重点区域（如监狱周边的监控点）。
执行查询： 系统会按相似度展示抓拍结果，您可以确认哪些照片确为该嫌疑人。
身份确认：
如果抓拍到的照片模糊，可使用“身份确认”功能，通过人脸比对或身份证号检索嫌疑人在库中的实名信息，确保目标无误。
第二阶段：轨迹研判（还原逃跑路线）
生成轨迹：
在“智图研判”的搜索结果中，勾选确认是该嫌疑人的抓拍记录。
点击“轨迹描绘 -> 智能轨迹”，系统会在地图上自动串联该嫌疑人在各个卡口出现的先后顺序。
地图研判： 观察地图上的轨迹线，判断其逃跑的方向（例如是否向车站、高速口或偏僻山区移动）。
视频回放：
在轨迹点位上点击“视频回放”，查看嫌疑人经过卡口时的动态行为（如是否有接应车辆、穿着是否改变、是否有同行人员）。
第三阶段：实时布控（全城拦截）
人脸布控（个体布控）：
进入“多维预警 -> 个体布控 -> 人脸布控”。
任务设置： 上传嫌疑人照片，设置预警相似度（建议设为80%以上以提高准确率）。
布控范围： 勾选全城的关键交通枢纽（车站、码头、机场）、出城道路卡口及重点场所（旅馆、网吧）。
推送设置： 开启“预警推送”，确保一旦嫌疑人出现在任何抓拍机前，系统能立即通过 PC 端弹窗或 Android 移动客户端通知办案民警。
车辆布控（如有发现涉案车辆）：
如果在回放中发现嫌疑人乘坐了特定车辆，进入“车辆布控”输入车牌号进行布控。
第四阶段：智能战法（排查帮凶与落脚点）
同行人分析：
进入“智能战法 -> 人脸技战法 -> 同行人”。
分析嫌疑人在逃跑过程中，是否有连续出现在多个卡口的共同人员。这有助于挖出接应者或潜伏的帮凶。
人员停留点/徘徊分析：
使用“人员停留点”分析，找出嫌疑人轨迹消失时间较长的坐标，这些地方极可能是其临时藏匿的窝点。
使用“人员徘徊”分析，查看是否有可疑人员在监狱周边反复出现，判断是否存在预谋越狱的迹象。
第五阶段：移动实战（现场搜捕）
APP实时预警：
搜捕民警登录 Android 移动客户端。
开启“消息通知”，实时接收布控报警。
现场搜图：
如果民警在搜捕现场发现疑似人员，可直接通过 APP 的“图片搜脸”或“身份确认”功能，现场拍照并即时比对后台数据库进行核实。
操作提示：
线索库管理： 过程中发现的所有关键照片、视频截图和轨迹，应随时点击“加入线索库”，方便后续合并研判和导出作为证据。
权限注意： 确保您的账号具有“实战工作台”和“多维预警”的相关操作权限。
（注：以上操作流程基于文档中关于公安场景查找走失人员及追踪犯罪嫌疑人的合法应用描述。）

上述给出了完整的流程，仿佛要马上把犯人抓住。但是事实上并不是这样。要一步一步来。而且给出了分支：
若锁定逃窜车辆，输入车牌号实施布控。
但是转变成具体操作时候，不能有分支情况。

Gemini更新了操作：


根据您的要求，以下是针对“昨日下午越狱犯人追踪”任务的唯一标准线性操作序列。该序列不设分支，不包含车辆搜索及同行人搜索，仅针对嫌疑人本身进行定位、溯源与实时布控。
第一阶段：定位嫌疑人最后轨迹
执行图片搜索：
进入【智能搜索】->【智图研判】模块。
点击上传框，上传嫌疑人清晰正面照片。
将【时间范围】修改为：起始时间（昨日下午越狱时刻）至 当前时间。
点击【查询】按钮获取所有抓拍记录。
生成智能轨迹：
在搜索结果列表中，点击左上角的【轨迹描绘】按钮。
点击【智能轨迹】。
观察右侧地图区域，查看由各抓拍点位连成的轨迹线，锁定嫌疑人最后一次出现的地理坐标。
第二阶段：核实详细档案
确认身份关联：
点击轨迹中最后一次抓拍的图片，在弹出的“详情弹框”中点击【身份确认】。
在结果中确认该人像与库中嫌疑人实名信息一致。
调取全量档案：
在身份确认结果下方点击【查看档案】（跳转至【人员档案】）。
查看档案中的“体貌特征”和“常用落脚点”，记录其过往行为标签。
第三阶段：部署实时布控
下发人脸布控任务：
进入【多维预警】->【个体布控】->【人脸布控】。
点击【新增布控】，上传嫌疑人照片。
【布控有效期】设为：自定义（未来72小时或更长）。
【布控地点】点击“地图选点”，框选全城交通枢纽、出城口及重点区域。
【最小预警相似度】输入：85%。
点击【保存】。
第四阶段：移动终端联动
开启移动端接收：
要求所有参战民警打开手机【Android 移动客户端】。
进入移动端【个人中心】->【消息设置】，将“人脸报警”相似度阈值调整为：85。
开启“消息通知”中的【声音】和【震动】。
第五阶段：证据留存
归档研判线索：
回到 PC 端【智图研判】界面。
勾选该嫌疑人所有关键轨迹点的抓拍记录，点击【加入线索库】。
操作完成，等待系统实时报警推送。

但这还是多层级的。

感悟：有说明书还是很有必要的。要是不让AI解读说明书指导我操作，我都不知道要怎么干。只有丰富经验的专家会干。但是基层民警不会干。

所以说，说明书是有意义的。怎么将说明书的内容让插件调用呢？要从 agent 的流程中开一个口子。

但是，如果我只是简单问一下今天的天气呢？这就是planner该做的事情：调用天气接口，还是查看说明书进而生成操作步骤？

接下来有了步骤，去执行，才是浏览器agent的事情。

我该了解一下agent的流程是怎么做的，才能知道怎么改造planner。知道怎么改造planner，才知道怎么加后端，怎么用agent。

所以，无论如何，我还是得看看代码。不懂代码，无从下手。

# 实验结果

终止制作PPT。转向理解代码，目的是知道怎么引向后端。