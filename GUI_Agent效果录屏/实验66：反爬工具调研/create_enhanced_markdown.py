#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""åˆ›å»ºå¢å¼ºç‰ˆMarkdown"""

import re
import sys
import json
import html
from bs4 import BeautifulSoup
from collections import Counter

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

def extract_enhanced_content(html_file):
    """æå–å¢å¼ºå†…å®¹"""

    with open(html_file, 'r', encoding='utf-8') as f:
        content = f.read()

    soup = BeautifulSoup(content, 'html.parser')

    items = []
    authors = []
    topics = []

    # æŸ¥æ‰¾æ‰€æœ‰å›ç­”å¡ç‰‡
    cards = soup.find_all(attrs={'data-zop': True})

    for i, card in enumerate(cards, 1):
        try:
            # è§£ædata-zop
            zop_str = card.get('data-zop', '{}')
            zop_data = json.loads(html.unescape(zop_str))

            # æå–é—®é¢˜æ ‡é¢˜
            title_elem = card.select_one('.ContentItem-title a')
            title = title_elem.get_text(strip=True) if title_elem else zop_data.get('title', '')

            # æå–é—®é¢˜é“¾æ¥
            question_link = ''
            if title_elem and title_elem.get('href'):
                href = title_elem['href']
                if href.startswith('//'):
                    question_link = 'https:' + href
                elif href.startswith('/'):
                    question_link = 'https://www.zhihu.com' + href
                else:
                    question_link = href

            # æå–ä½œè€…ä¿¡æ¯
            author_name_elem = card.select_one('.AuthorInfo-name')
            author_name = author_name_elem.get_text(strip=True) if author_name_elem else zop_data.get('authorName', '')

            # æ”¶é›†ä½œè€…
            if author_name:
                authors.append(author_name)

            author_link_elem = card.select_one('.AuthorInfo-name')
            author_link = ''
            if author_link_elem and author_link_elem.get('href'):
                href = author_link_elem['href']
                if href.startswith('//'):
                    author_link = 'https:' + href
                elif href.startswith('/'):
                    author_link = 'https://www.zhihu.com' + href

            # æå–ä½œè€…å¤´åƒ
            avatar_elem = card.select_one('.AuthorInfo-avatarWrapper img')
            avatar_url = avatar_elem.get('src', '') if avatar_elem else ''

            # æå–æ­£æ–‡å†…å®¹
            content_div = card.select_one('.RichContent-inner')
            content_text = ''
            if content_div:
                # æå–æ®µè½
                paragraphs = content_div.find_all('p')
                content_text = '\n\n'.join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])

            # æå–å…ƒæ•°æ®(itemId)
            item_id = zop_data.get('itemId', '')

            # æå–æ‘˜è¦(å¦‚æœæœ‰)
            excerpt_elem = card.select_one('.RichContent-inner')
            excerpt = ''
            if excerpt_elem:
                text = excerpt_elem.get_text(strip=True)
                excerpt = text[:150] + '...' if len(text) > 150 else text

            item = {
                'index': i,
                'title': title,
                'question_link': question_link,
                'author_name': author_name,
                'author_link': author_link,
                'avatar': avatar_url,
                'content': content_text,
                'excerpt': excerpt,
                'item_id': item_id,
            }

            items.append(item)

        except Exception as e:
            print(f"å¤„ç†ç¬¬{i}ä¸ªå¡ç‰‡æ—¶å‡ºé”™: {e}")
            continue

    return items, authors

def create_enhanced_markdown(items, authors, output_file):
    """åˆ›å»ºå¢å¼ºç‰ˆMarkdown"""

    # ç»Ÿè®¡ä¿¡æ¯
    total_items = len(items)
    unique_authors = len(set(authors))

    # åˆ›å»ºç›®å½•
    toc = "\n".join([f"{i}. [{item['title']}](#{item['index']}-{item['title'][:30].replace(' ', '-')})" for i, item in enumerate(items, 1)])

    # ç”ŸæˆMarkdown
    md_content = f"""# èµåŒè¶…è¿‡10Kçš„å›ç­” - çŸ¥ä¹æ”¶è—å¤¹

<div align="center">

**æ”¶å½•æ•°é‡**: {total_items} ä¸ªé«˜è´¨é‡å›ç­”
**ç‹¬ç‰¹ä½œè€…**: {unique_authors} ä½
**æ”¶å½•æ—¶é—´**: 2025-01-17

</div>

---

## ğŸ“‹ ç›®å½•

{toc}

---

## ğŸ“Š æ”¶è—å¤¹ç»Ÿè®¡

- ğŸ“ **æ€»å›ç­”æ•°**: {total_items}
- ğŸ‘¤ **æ¶‰åŠä½œè€…**: {unique_authors}
- ğŸ’ **è´¨é‡æ ‡å‡†**: èµåŒæ•°è¶…è¿‡10K
- ğŸ“‚ **æ”¶è—å¤¹**: "èµåŒè¶…è¿‡10Kçš„å›ç­”"

---

## ğŸ“– ç²¾é€‰å†…å®¹åˆ—è¡¨

"""

    for item in items:
        md_content += f"""
### {item['index']}. {item['title']}

<div align="center">

**ä½œè€…**: [{item['author_name']}]({item['author_link']})
**å›ç­”ID**: `{item['item_id']}`
**é“¾æ¥**: [æŸ¥çœ‹åŸå›ç­”]({item['question_link']})

</div>

---

**å†…å®¹æ‘˜è¦**:

> {item['excerpt'] if item['excerpt'] else '*ï¼ˆç‚¹å‡»ä¸Šæ–¹é“¾æ¥æŸ¥çœ‹å®Œæ•´å›ç­”ï¼‰*'}

---

**å¿«é€Ÿå¯¼èˆª**:
- ğŸ”— [å®Œæ•´å›ç­”]({item['question_link']})
- ğŸ‘¤ [ä½œè€…ä¸»é¡µ]({item['author_link']})
- ğŸ’¬ [æŸ¥çœ‹è¯„è®º]({item['question_link']})

---

"""

    md_content += """
## ğŸ” ä½¿ç”¨è¯´æ˜

1. **æŸ¥çœ‹å†…å®¹**: ç‚¹å‡»æ¯ä¸ªå›ç­”ä¸‹æ–¹çš„"æŸ¥çœ‹åŸå›ç­”"é“¾æ¥å³å¯è·³è½¬åˆ°çŸ¥ä¹é¡µé¢
2. **ä½œè€…ä¿¡æ¯**: ç‚¹å‡»ä½œè€…åç§°å¯ä»¥è®¿é—®ä½œè€…ä¸»é¡µ
3. **å†…å®¹è´¨é‡**: æœ¬æ”¶è—å¤¹æ‰€æœ‰å›ç­”èµåŒæ•°å‡è¶…è¿‡10K
4. **æŒç»­æ›´æ–°**: æ”¶è—å¤¹ä¼šä¸å®šæœŸæ›´æ–°

## ğŸ“Œ æ•°æ®æ¥æº

- **æ¥æº**: çŸ¥ä¹æ”¶è—å¤¹
- **æ”¶è—å¤¹åç§°**: "èµåŒè¶…è¿‡10Kçš„å›ç­”"
- **æå–æ—¶é—´**: 2025-01-17
- **å·¥å…·**: HTMLç»“æ„åˆ†æ + BeautifulSoup

## âš ï¸ å…è´£å£°æ˜

æœ¬Markdownæ–‡æ¡£ä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨,æ‰€æœ‰å†…å®¹ç‰ˆæƒå½’åŸä½œè€…æ‰€æœ‰ã€‚
å¦‚éœ€æŸ¥çœ‹å®Œæ•´å†…å®¹,è¯·è®¿é—®çŸ¥ä¹åŸé¡µé¢ã€‚

---

<div align="center">

**Made with â¤ï¸ by çŸ¥ä¹å†…å®¹åˆ†æå·¥å…·**

</div>
"""

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(md_content)

    print(f"âœ“ å¢å¼ºç‰ˆMarkdownæ–‡ä»¶å·²ä¿å­˜: {output_file}")

def main():
    html_file = r'c:\Users\admin\Documents\GitHub\fri\20251216GUIAgent\GUI_Agentæ•ˆæœå½•å±\å®éªŒ66ï¼šåçˆ¬å·¥å…·è°ƒç ”\collection_page.html'
    output_file = r'c:\Users\admin\Documents\GitHub\fri\20251216GUIAgent\GUI_Agentæ•ˆæœå½•å±\å®éªŒ66ï¼šåçˆ¬å·¥å…·è°ƒç ”\æ”¶è—å¤¹å†…å®¹_å¢å¼ºç‰ˆ.md'

    print("=" * 80)
    print("åˆ›å»ºå¢å¼ºç‰ˆMarkdownæ–‡æ¡£")
    print("=" * 80)
    print()

    items, authors = extract_enhanced_content(html_file)

    print(f"æˆåŠŸæå– {len(items)} ä¸ªå›ç­”")
    print(f"æ¶‰åŠ {len(set(authors))} ä½ä½œè€…\n")

    create_enhanced_markdown(items, authors, output_file)

    print("\n" + "=" * 80)
    print("è½¬æ¢å®Œæˆ!")
    print("=" * 80)

if __name__ == '__main__':
    main()
